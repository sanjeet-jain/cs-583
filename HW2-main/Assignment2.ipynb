{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Build a CNN for image recognition.\n",
    "\n",
    "## Due Date:  March 31, 11:59PM\n",
    "\n",
    "### Name: SANJEET VINOD JAIN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "1. In this assignment, you will build Convolutional Neural Network to classify CIFAR-10 Images.\n",
    "2. You can directly load dataset from many deep learning packages.\n",
    "3. You can use any deep learning packages such as pytorch, keras or tensorflow for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements:\n",
    "\n",
    "1. You need to load cifar 10 data and split the entire training dataset into training and validation.\n",
    "2. You will implement a CNN model to classify cifar 10 images with provided structure.\n",
    "3. You need to plot the training and validation accuracy or loss obtained from above step.\n",
    "4. Then you can use tuned hyper-parameters to train using the entire training dataset.\n",
    "5. You should report the testing accuracy using the model with complete data.\n",
    "6. You may try to change the structure (e.g, add BN layer or dropout layer,...) and analyze your findings.\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization (BN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Batch Normalization is a technique to speed up training and help make the model more stable.\n",
    "- In simple words, batch normalization is just another network layer that gets inserted between a hidden layer and the next hidden layer. Its job is to take the outputs from the first hidden layer and normalize them before passing them on as the input of the next hidden layer.\n",
    "\n",
    "- For more detailed information, you may refer to the original paper: https://arxiv.org/pdf/1502.03167.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BN Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: Values of $x$ over a mini-batch: $\\mathbf{B}$ = $\\{x_1,..., x_m\\};$\n",
    "- Output: $\\{y_i = BN_{\\gamma,\\beta}(x_i)\\}$, $\\gamma, \\beta$ are learnable parameters\n",
    "\n",
    "Normalization of the Input:\n",
    "$$\\mu_{\\mathbf{B}} = \\frac{1}{m}\\sum_{i=1}^m x_i$$\n",
    "$$\\sigma_{\\mathbf{B}}^2 = \\frac{1}{m}\\sum_{i=1}^m (x_i - \\mu_{\\mathbf{B}})^2$$\n",
    "$$\\hat{x_i} = \\frac{x_i - \\mu_{\\mathbf{B}}}{\\sqrt{\\sigma_{\\mathbf{B}}}^2 + \\epsilon}$$\n",
    "Re-scaling and Offsetting:\n",
    "$$y_i = \\gamma \\hat{x_i} + \\beta = BN_{\\gamma,\\beta}(x_i)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of BN:\n",
    "1. Improves gradient flow through the network.\n",
    "2. Allows use of saturating nonlinearities and higher learning rates.\n",
    "3. Makes weights easier to initialize.\n",
    "4. Act as a form of regularization and may reduce the need for dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The batch normalization layer has already been implemented in many packages. You may simply call the function to build the layer. For example: torch.nn.BatchNorm2d() using pytroch package, keras.layers.BatchNormalization() using keras package.\n",
    "- The location of BN layer: Please make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just checking my tensor flow setup with my gpu\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Load Cifar-10 Data\n",
    "# This is just an example, you may load dataset from other packages.\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "### If you can not load keras dataset, un-comment these two lines.\n",
    "#import ssl\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels (5 points)\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Implement a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def to_one_hot(y, num_class=10):\n",
    "   new_y = []\n",
    "   for values in y :\n",
    "      encoder = np.zeros(num_class)\n",
    "      encoder[values] = 1\n",
    "      new_y.append(encoder)\n",
    "   return np.asarray(new_y)\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets (5 points)\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets: \n",
    "* a training set containing 40K samples: x_tr, y_tr\n",
    "* a validation set containing 10K samples: x_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_train,y_train_vec,test_size=0.2,shuffle=True)\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters (50 points)\n",
    "\n",
    "- Build a convolutional neural network model using the below structure:\n",
    "\n",
    "- It should have a structure of: Conv - ReLU - Max Pool - ConV - ReLU - Max Pool - Dense - ReLU - Dense - Softmax\n",
    "\n",
    "- In the graph 3@32x32 means the dimension of input image, 32@30x30 means it has 32 filters and the dimension now becomes 30x30 after the convolution.\n",
    "- All convolutional layers (Conv) should have stride = 1 and no padding.\n",
    "- Max Pooling has a pool size of 2 by 2.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"network.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You may use the validation data to tune the hyper-parameters (e.g., learning rate, and optimization algorithm)\n",
    "- Do NOT use test data for hyper-parameter tuning!!!\n",
    "- Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 64)        32832     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               590080    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 626,378\n",
      "Trainable params: 626,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model optimizer and loss function\n",
    "from keras import optimizers\n",
    "\n",
    "lr = 0.0001\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(learning_rate = lr), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 6s 5ms/step - loss: 2.7326 - acc: 0.3509 - val_loss: 1.5034 - val_acc: 0.4700\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3475 - acc: 0.5285 - val_loss: 1.3015 - val_acc: 0.5470\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.1283 - acc: 0.6076 - val_loss: 1.2232 - val_acc: 0.5807\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9780 - acc: 0.6611 - val_loss: 1.1713 - val_acc: 0.6043\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8541 - acc: 0.7068 - val_loss: 1.1998 - val_acc: 0.6124\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7493 - acc: 0.7420 - val_loss: 1.1342 - val_acc: 0.6347\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6540 - acc: 0.7766 - val_loss: 1.1531 - val_acc: 0.6308\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.5695 - acc: 0.8066 - val_loss: 1.1686 - val_acc: 0.6293\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4900 - acc: 0.8344 - val_loss: 1.1761 - val_acc: 0.6441\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4243 - acc: 0.8565 - val_loss: 1.2691 - val_acc: 0.6382\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.3641 - acc: 0.8800 - val_loss: 1.3745 - val_acc: 0.6328\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.3114 - acc: 0.8975 - val_loss: 1.4187 - val_acc: 0.6471\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2604 - acc: 0.9153 - val_loss: 1.5059 - val_acc: 0.6387\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2208 - acc: 0.9285 - val_loss: 1.5161 - val_acc: 0.6427\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1854 - acc: 0.9401 - val_loss: 1.5828 - val_acc: 0.6501\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1572 - acc: 0.9517 - val_loss: 1.6700 - val_acc: 0.6416\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1310 - acc: 0.9600 - val_loss: 1.7350 - val_acc: 0.6495\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1121 - acc: 0.9666 - val_loss: 1.8383 - val_acc: 0.6375\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0967 - acc: 0.9707 - val_loss: 1.8115 - val_acc: 0.6501\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0844 - acc: 0.9749 - val_loss: 1.9900 - val_acc: 0.6461\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0756 - acc: 0.9776 - val_loss: 2.0265 - val_acc: 0.6454\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0650 - acc: 0.9805 - val_loss: 1.9978 - val_acc: 0.6418\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0575 - acc: 0.9837 - val_loss: 2.2873 - val_acc: 0.6419\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0543 - acc: 0.9840 - val_loss: 2.2102 - val_acc: 0.6515\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0500 - acc: 0.9851 - val_loss: 2.2607 - val_acc: 0.6392\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0468 - acc: 0.9862 - val_loss: 2.3431 - val_acc: 0.6442\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0428 - acc: 0.9875 - val_loss: 2.4468 - val_acc: 0.6553\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0423 - acc: 0.9873 - val_loss: 2.4119 - val_acc: 0.6479\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0386 - acc: 0.9882 - val_loss: 2.6364 - val_acc: 0.6502\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0387 - acc: 0.9888 - val_loss: 2.7969 - val_acc: 0.6444\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0364 - acc: 0.9894 - val_loss: 2.6254 - val_acc: 0.6538\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0368 - acc: 0.9886 - val_loss: 2.6182 - val_acc: 0.6545\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0356 - acc: 0.9899 - val_loss: 2.8694 - val_acc: 0.6446\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0346 - acc: 0.9901 - val_loss: 2.7806 - val_acc: 0.6489\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0346 - acc: 0.9898 - val_loss: 2.8882 - val_acc: 0.6587\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0308 - acc: 0.9906 - val_loss: 2.7864 - val_acc: 0.6542\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0312 - acc: 0.9906 - val_loss: 2.8131 - val_acc: 0.6504\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0312 - acc: 0.9899 - val_loss: 3.0810 - val_acc: 0.6609\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0372 - acc: 0.9883 - val_loss: 3.1947 - val_acc: 0.6515\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0358 - acc: 0.9890 - val_loss: 2.8321 - val_acc: 0.6452\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0318 - acc: 0.9902 - val_loss: 3.1664 - val_acc: 0.6463\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0348 - acc: 0.9894 - val_loss: 3.0907 - val_acc: 0.6444\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0323 - acc: 0.9898 - val_loss: 3.3455 - val_acc: 0.6418\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0351 - acc: 0.9898 - val_loss: 3.0618 - val_acc: 0.6453\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0316 - acc: 0.9906 - val_loss: 3.3343 - val_acc: 0.6528\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0315 - acc: 0.9904 - val_loss: 3.3800 - val_acc: 0.6412\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0300 - acc: 0.9906 - val_loss: 3.4878 - val_acc: 0.6522\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0333 - acc: 0.9901 - val_loss: 3.5237 - val_acc: 0.6538\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0326 - acc: 0.9907 - val_loss: 3.4269 - val_acc: 0.6575\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0324 - acc: 0.9902 - val_loss: 3.4623 - val_acc: 0.6570\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0335 - acc: 0.9902 - val_loss: 3.4146 - val_acc: 0.6528\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0340 - acc: 0.9901 - val_loss: 3.4767 - val_acc: 0.6519\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0316 - acc: 0.9901 - val_loss: 3.4434 - val_acc: 0.6419\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0308 - acc: 0.9906 - val_loss: 3.6534 - val_acc: 0.6538\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0333 - acc: 0.9906 - val_loss: 3.7215 - val_acc: 0.6500\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0333 - acc: 0.9902 - val_loss: 4.0187 - val_acc: 0.6434\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0360 - acc: 0.9896 - val_loss: 3.9545 - val_acc: 0.6554\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0324 - acc: 0.9904 - val_loss: 3.7200 - val_acc: 0.6572\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0309 - acc: 0.9908 - val_loss: 4.0612 - val_acc: 0.6453\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0299 - acc: 0.9905 - val_loss: 3.9594 - val_acc: 0.6346\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0329 - acc: 0.9906 - val_loss: 4.0510 - val_acc: 0.6476\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0329 - acc: 0.9905 - val_loss: 3.8312 - val_acc: 0.6467\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0326 - acc: 0.9901 - val_loss: 3.9939 - val_acc: 0.6555\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0318 - acc: 0.9906 - val_loss: 4.4496 - val_acc: 0.6539\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0309 - acc: 0.9905 - val_loss: 4.1204 - val_acc: 0.6538\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0322 - acc: 0.9905 - val_loss: 4.3969 - val_acc: 0.6470\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0342 - acc: 0.9901 - val_loss: 4.5052 - val_acc: 0.6594\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0367 - acc: 0.9901 - val_loss: 4.4750 - val_acc: 0.6280\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0345 - acc: 0.9901 - val_loss: 4.1391 - val_acc: 0.6391\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0325 - acc: 0.9905 - val_loss: 4.1388 - val_acc: 0.6491\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0337 - acc: 0.9899 - val_loss: 4.3720 - val_acc: 0.6606\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0379 - acc: 0.9898 - val_loss: 4.6952 - val_acc: 0.6521\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0380 - acc: 0.9895 - val_loss: 3.8172 - val_acc: 0.6491\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0366 - acc: 0.9899 - val_loss: 4.4881 - val_acc: 0.6540\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0306 - acc: 0.9916 - val_loss: 4.4764 - val_acc: 0.6510\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0347 - acc: 0.9904 - val_loss: 4.9797 - val_acc: 0.6466\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0371 - acc: 0.9902 - val_loss: 4.1024 - val_acc: 0.6527\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0340 - acc: 0.9902 - val_loss: 4.7339 - val_acc: 0.6619\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0325 - acc: 0.9911 - val_loss: 4.0737 - val_acc: 0.6394\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0346 - acc: 0.9907 - val_loss: 4.6928 - val_acc: 0.6507\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0351 - acc: 0.9901 - val_loss: 4.6381 - val_acc: 0.6502\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0356 - acc: 0.9908 - val_loss: 4.7145 - val_acc: 0.6545\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0344 - acc: 0.9905 - val_loss: 4.8448 - val_acc: 0.6621\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0358 - acc: 0.9910 - val_loss: 4.3895 - val_acc: 0.6510\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0335 - acc: 0.9907 - val_loss: 4.7001 - val_acc: 0.6532\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0357 - acc: 0.9897 - val_loss: 4.5427 - val_acc: 0.6543\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0386 - acc: 0.9900 - val_loss: 5.6575 - val_acc: 0.6575\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0399 - acc: 0.9897 - val_loss: 4.3639 - val_acc: 0.6526\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0360 - acc: 0.9899 - val_loss: 5.2233 - val_acc: 0.6396\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0384 - acc: 0.9890 - val_loss: 5.2667 - val_acc: 0.6584\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0448 - acc: 0.9880 - val_loss: 4.7750 - val_acc: 0.6404\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0398 - acc: 0.9902 - val_loss: 5.1088 - val_acc: 0.6578\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0422 - acc: 0.9888 - val_loss: 5.1777 - val_acc: 0.6455\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0436 - acc: 0.9882 - val_loss: 4.8707 - val_acc: 0.6447\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0405 - acc: 0.9896 - val_loss: 5.1794 - val_acc: 0.6474\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0379 - acc: 0.9900 - val_loss: 5.0447 - val_acc: 0.6628\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0391 - acc: 0.9898 - val_loss: 4.7307 - val_acc: 0.6440\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0389 - acc: 0.9897 - val_loss: 5.1584 - val_acc: 0.6541\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0408 - acc: 0.9891 - val_loss: 5.0449 - val_acc: 0.6493\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0386 - acc: 0.9897 - val_loss: 5.7595 - val_acc: 0.6401\n"
     ]
    }
   ],
   "source": [
    "# Train the model and store model parameters/loss values\n",
    "history_model_1 = model.fit(x_tr, y_tr, batch_size=40, epochs=100, validation_data=(x_val, y_val))\n",
    "model.save('model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot the training and validation loss curve versus epochs. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history_model_1.history['acc']\n",
    "val_acc = history_model_1.history['val_acc']\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train (again) and evaluate the model (5 points)\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<Compile your model again (using the same hyper-parameters you tuned above)>\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape=(32, 32, 3)))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (4, 4), activation = 'relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(learning_rate = 0.0001) , metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.6468 - acc: 0.3521\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3796 - acc: 0.5155\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.1927 - acc: 0.5857\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.0499 - acc: 0.6365\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.9441 - acc: 0.6748\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.8493 - acc: 0.7096\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.7679 - acc: 0.7387\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.6943 - acc: 0.7650\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.6266 - acc: 0.7887\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5617 - acc: 0.8104\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5056 - acc: 0.8302\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4537 - acc: 0.8459\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.4034 - acc: 0.8636\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3611 - acc: 0.8797\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3243 - acc: 0.8914\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2843 - acc: 0.9056\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2538 - acc: 0.9171\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2254 - acc: 0.9263\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2011 - acc: 0.9343\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1789 - acc: 0.9411\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1596 - acc: 0.9483\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1460 - acc: 0.9534\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1288 - acc: 0.9589\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1198 - acc: 0.9617\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1095 - acc: 0.9647\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1029 - acc: 0.9675\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0942 - acc: 0.9698\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0859 - acc: 0.9724\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0833 - acc: 0.9741\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0776 - acc: 0.9747\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0754 - acc: 0.9766\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0706 - acc: 0.9778\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0679 - acc: 0.9786\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0700 - acc: 0.9773\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0626 - acc: 0.9802\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0627 - acc: 0.9797\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0637 - acc: 0.9801\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0618 - acc: 0.9803\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0609 - acc: 0.9800\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0576 - acc: 0.9817\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0591 - acc: 0.9824\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0576 - acc: 0.9815\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0569 - acc: 0.9825\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0566 - acc: 0.9824\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0578 - acc: 0.9822\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0536 - acc: 0.9839\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0510 - acc: 0.9844\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0598 - acc: 0.9826\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0585 - acc: 0.9824\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0543 - acc: 0.9825\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0549 - acc: 0.9834\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0555 - acc: 0.9838\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0554 - acc: 0.9838\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0535 - acc: 0.9835\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0563 - acc: 0.9835\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0562 - acc: 0.9835\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0563 - acc: 0.9840\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0573 - acc: 0.9825\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0569 - acc: 0.9838\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0509 - acc: 0.9855\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0541 - acc: 0.9838\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0497 - acc: 0.9850\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0534 - acc: 0.9848\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0596 - acc: 0.9830\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0538 - acc: 0.9845\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0515 - acc: 0.9860\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0519 - acc: 0.9855\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0546 - acc: 0.9846\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0504 - acc: 0.9865\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0518 - acc: 0.9859\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0525 - acc: 0.9859\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0533 - acc: 0.9860\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0521 - acc: 0.9854\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0535 - acc: 0.9857\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0456 - acc: 0.9867\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0525 - acc: 0.9852\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0483 - acc: 0.9868\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0512 - acc: 0.9860\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0563 - acc: 0.9849\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0509 - acc: 0.9859\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0549 - acc: 0.9856\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0574 - acc: 0.9849\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0542 - acc: 0.9860\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0578 - acc: 0.9852\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0493 - acc: 0.9868\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0589 - acc: 0.9852\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0584 - acc: 0.9847\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0528 - acc: 0.9866\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0546 - acc: 0.9856\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0548 - acc: 0.9860\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0526 - acc: 0.9867\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0542 - acc: 0.9856\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0532 - acc: 0.9863\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0504 - acc: 0.9871\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0551 - acc: 0.9860\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0569 - acc: 0.9868\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0542 - acc: 0.9867\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0523 - acc: 0.9870\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0547 - acc: 0.9868\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0545 - acc: 0.9867\n"
     ]
    }
   ],
   "source": [
    "#<Train your model on the entire training set (50K samples)>\n",
    "\n",
    "history_model_2 = model.fit(x_train, y_train_vec, batch_size=40, epochs=100)\n",
    "model.save('model_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the model on the test set (5 points)\n",
    "\n",
    "Do NOT use the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 5.0970 - acc: 0.6392\n",
      "loss = 5.0970458984375\n",
      "accuracy = 0.63919997215271\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model performance (testing accuracy) on testing data.\n",
    "from keras.models import load_model\n",
    "curr_model = load_model('model_2.h5')\n",
    "lacc = curr_model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(lacc[0]))\n",
    "print('accuracy = ' + str(lacc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 5.9482 - acc: 0.6302\n",
      "loss = 5.948246002197266\n",
      "accuracy = 0.6302000284194946\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model performance (testing accuracy) on testing data.\n",
    "\n",
    "curr_model = load_model('model_1.h5')\n",
    "lacc = curr_model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(lacc[0]))\n",
    "print('accuracy = ' + str(lacc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building model with new structure (25 points)\n",
    "- In this section, you can build your model with adding new layers (e.g, BN layer or dropout layer, ...).\n",
    "- If you want to regularize a ```Conv/Dense layer```, you should place a ```Dropout layer``` before the ```Conv/Dense layer```.\n",
    "- You can try to compare their loss curve and testing accuracy and analyze your findings.\n",
    "- You need to try at lease two different model structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 30, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 12, 12, 64)        32832     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 12, 12, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               590080    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 627,786\n",
      "Trainable params: 627,082\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (4, 4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "temp_data = ImageDataGenerator( rotation_range=20, height_shift_range=0.2, width_shift_range=0.2, \n",
    "                               zoom_range = 0.2, shear_range = 0.2, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model optimizer and loss function\n",
    "lr = 0.0001\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(learning_rate=lr), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1000/1000 [==============================] - 16s 15ms/step - loss: 1.6966 - acc: 0.3906 - val_loss: 1.4487 - val_acc: 0.4799\n",
      "Epoch 2/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 1.4731 - acc: 0.4708 - val_loss: 1.3137 - val_acc: 0.5318\n",
      "Epoch 3/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 1.3766 - acc: 0.5098 - val_loss: 1.2442 - val_acc: 0.5650\n",
      "Epoch 4/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 1.3219 - acc: 0.5313 - val_loss: 1.2809 - val_acc: 0.5531\n",
      "Epoch 5/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 1.2678 - acc: 0.5492 - val_loss: 1.2237 - val_acc: 0.5786\n",
      "Epoch 6/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 1.2440 - acc: 0.5563 - val_loss: 1.1327 - val_acc: 0.6032\n",
      "Epoch 7/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 1.2040 - acc: 0.5690 - val_loss: 1.0012 - val_acc: 0.6441\n",
      "Epoch 8/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 1.1767 - acc: 0.5830 - val_loss: 1.0090 - val_acc: 0.6487\n",
      "Epoch 9/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 1.1445 - acc: 0.5942 - val_loss: 1.0160 - val_acc: 0.6450\n",
      "Epoch 10/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 1.1307 - acc: 0.6006 - val_loss: 1.0465 - val_acc: 0.6331\n",
      "Epoch 11/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 1.1049 - acc: 0.6097 - val_loss: 0.9933 - val_acc: 0.6664\n",
      "Epoch 12/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 1.0936 - acc: 0.6156 - val_loss: 0.9749 - val_acc: 0.6580\n",
      "Epoch 13/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 1.0757 - acc: 0.6208 - val_loss: 0.9799 - val_acc: 0.6563\n",
      "Epoch 14/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 1.0601 - acc: 0.6279 - val_loss: 0.9267 - val_acc: 0.6794\n",
      "Epoch 15/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 1.0432 - acc: 0.6327 - val_loss: 0.9733 - val_acc: 0.6629\n",
      "Epoch 16/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 1.0298 - acc: 0.6409 - val_loss: 0.9293 - val_acc: 0.6791\n",
      "Epoch 17/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 1.0232 - acc: 0.6406 - val_loss: 0.9570 - val_acc: 0.6762\n",
      "Epoch 18/150\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 1.0127 - acc: 0.6432 - val_loss: 0.9044 - val_acc: 0.6855\n",
      "Epoch 19/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.9971 - acc: 0.6520 - val_loss: 1.0215 - val_acc: 0.6567\n",
      "Epoch 20/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.9904 - acc: 0.6525 - val_loss: 1.0161 - val_acc: 0.6646\n",
      "Epoch 21/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.9786 - acc: 0.6556 - val_loss: 1.0330 - val_acc: 0.6649\n",
      "Epoch 22/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.9706 - acc: 0.6611 - val_loss: 0.8620 - val_acc: 0.7051\n",
      "Epoch 23/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.9599 - acc: 0.6614 - val_loss: 0.8099 - val_acc: 0.7168\n",
      "Epoch 24/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.9542 - acc: 0.6659 - val_loss: 0.8705 - val_acc: 0.7017\n",
      "Epoch 25/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.9413 - acc: 0.6695 - val_loss: 0.7925 - val_acc: 0.7248\n",
      "Epoch 26/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.9392 - acc: 0.6682 - val_loss: 0.8706 - val_acc: 0.6972\n",
      "Epoch 27/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.9315 - acc: 0.6734 - val_loss: 0.9714 - val_acc: 0.6675\n",
      "Epoch 28/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.9275 - acc: 0.6758 - val_loss: 0.8042 - val_acc: 0.7274\n",
      "Epoch 29/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.9199 - acc: 0.6759 - val_loss: 0.7771 - val_acc: 0.7341\n",
      "Epoch 30/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.9164 - acc: 0.6807 - val_loss: 0.8329 - val_acc: 0.7108\n",
      "Epoch 31/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.9086 - acc: 0.6823 - val_loss: 0.8996 - val_acc: 0.6929\n",
      "Epoch 32/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.9039 - acc: 0.6809 - val_loss: 0.7882 - val_acc: 0.7380\n",
      "Epoch 33/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8928 - acc: 0.6887 - val_loss: 0.8401 - val_acc: 0.7101\n",
      "Epoch 34/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8888 - acc: 0.6889 - val_loss: 0.8081 - val_acc: 0.7290\n",
      "Epoch 35/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8939 - acc: 0.6878 - val_loss: 0.8314 - val_acc: 0.7174\n",
      "Epoch 36/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8842 - acc: 0.6895 - val_loss: 0.9130 - val_acc: 0.6994\n",
      "Epoch 37/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8777 - acc: 0.6955 - val_loss: 0.7743 - val_acc: 0.7367\n",
      "Epoch 38/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8679 - acc: 0.6944 - val_loss: 0.7710 - val_acc: 0.7405\n",
      "Epoch 39/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.8781 - acc: 0.6937 - val_loss: 0.8413 - val_acc: 0.7204\n",
      "Epoch 40/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8620 - acc: 0.6978 - val_loss: 0.8288 - val_acc: 0.7185\n",
      "Epoch 41/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.8660 - acc: 0.6978 - val_loss: 0.7555 - val_acc: 0.7377\n",
      "Epoch 42/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8564 - acc: 0.6992 - val_loss: 0.7736 - val_acc: 0.7377\n",
      "Epoch 43/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8510 - acc: 0.7035 - val_loss: 0.7974 - val_acc: 0.7293\n",
      "Epoch 44/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8495 - acc: 0.7042 - val_loss: 0.8293 - val_acc: 0.7242\n",
      "Epoch 45/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.8522 - acc: 0.7016 - val_loss: 0.8347 - val_acc: 0.7158\n",
      "Epoch 46/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.8420 - acc: 0.7053 - val_loss: 0.7521 - val_acc: 0.7436\n",
      "Epoch 47/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.8409 - acc: 0.7071 - val_loss: 0.7298 - val_acc: 0.7494\n",
      "Epoch 48/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.8408 - acc: 0.7067 - val_loss: 0.8668 - val_acc: 0.7097\n",
      "Epoch 49/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8338 - acc: 0.7096 - val_loss: 0.8088 - val_acc: 0.7246\n",
      "Epoch 50/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8276 - acc: 0.7109 - val_loss: 0.7824 - val_acc: 0.7336\n",
      "Epoch 51/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8289 - acc: 0.7106 - val_loss: 0.8061 - val_acc: 0.7314\n",
      "Epoch 52/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8220 - acc: 0.7113 - val_loss: 0.7588 - val_acc: 0.7462\n",
      "Epoch 53/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.8132 - acc: 0.7169 - val_loss: 0.7168 - val_acc: 0.7584\n",
      "Epoch 54/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8164 - acc: 0.7143 - val_loss: 0.7566 - val_acc: 0.7449\n",
      "Epoch 55/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8129 - acc: 0.7171 - val_loss: 0.6949 - val_acc: 0.7644\n",
      "Epoch 56/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8152 - acc: 0.7129 - val_loss: 0.7666 - val_acc: 0.7387\n",
      "Epoch 57/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8102 - acc: 0.7167 - val_loss: 0.7593 - val_acc: 0.7453\n",
      "Epoch 58/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8005 - acc: 0.7225 - val_loss: 0.7491 - val_acc: 0.7427\n",
      "Epoch 59/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8033 - acc: 0.7215 - val_loss: 0.6854 - val_acc: 0.7668\n",
      "Epoch 60/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7970 - acc: 0.7214 - val_loss: 0.7136 - val_acc: 0.7563\n",
      "Epoch 61/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.8022 - acc: 0.7207 - val_loss: 0.9576 - val_acc: 0.6891\n",
      "Epoch 62/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7866 - acc: 0.7268 - val_loss: 0.7879 - val_acc: 0.7404\n",
      "Epoch 63/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7964 - acc: 0.7231 - val_loss: 0.7210 - val_acc: 0.7549\n",
      "Epoch 64/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7946 - acc: 0.7235 - val_loss: 0.7082 - val_acc: 0.7588\n",
      "Epoch 65/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7861 - acc: 0.7240 - val_loss: 0.8911 - val_acc: 0.7086\n",
      "Epoch 66/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7838 - acc: 0.7277 - val_loss: 0.7918 - val_acc: 0.7364\n",
      "Epoch 67/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7814 - acc: 0.7254 - val_loss: 0.8000 - val_acc: 0.7322\n",
      "Epoch 68/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7825 - acc: 0.7268 - val_loss: 0.7343 - val_acc: 0.7543\n",
      "Epoch 69/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7772 - acc: 0.7290 - val_loss: 0.7521 - val_acc: 0.7474\n",
      "Epoch 70/150\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.7753 - acc: 0.7297 - val_loss: 0.7661 - val_acc: 0.7484\n",
      "Epoch 71/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7745 - acc: 0.7291 - val_loss: 0.8058 - val_acc: 0.7407\n",
      "Epoch 72/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7687 - acc: 0.7289 - val_loss: 0.7115 - val_acc: 0.7617\n",
      "Epoch 73/150\n",
      "1000/1000 [==============================] - 13s 12ms/step - loss: 0.7754 - acc: 0.7310 - val_loss: 0.6625 - val_acc: 0.7767\n",
      "Epoch 74/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7643 - acc: 0.7320 - val_loss: 0.7431 - val_acc: 0.7533\n",
      "Epoch 75/150\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.7667 - acc: 0.7326 - val_loss: 0.8543 - val_acc: 0.7270\n",
      "Epoch 76/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7632 - acc: 0.7351 - val_loss: 0.7162 - val_acc: 0.7572\n",
      "Epoch 77/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7675 - acc: 0.7307 - val_loss: 0.7022 - val_acc: 0.7643\n",
      "Epoch 78/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7645 - acc: 0.7339 - val_loss: 0.7831 - val_acc: 0.7397\n",
      "Epoch 79/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7621 - acc: 0.7361 - val_loss: 0.7378 - val_acc: 0.7552\n",
      "Epoch 80/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7556 - acc: 0.7345 - val_loss: 0.8028 - val_acc: 0.7390\n",
      "Epoch 81/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7497 - acc: 0.7385 - val_loss: 0.7062 - val_acc: 0.7617\n",
      "Epoch 82/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7558 - acc: 0.7387 - val_loss: 0.8607 - val_acc: 0.7242\n",
      "Epoch 83/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7520 - acc: 0.7357 - val_loss: 0.7403 - val_acc: 0.7590\n",
      "Epoch 84/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7498 - acc: 0.7405 - val_loss: 0.6329 - val_acc: 0.7881\n",
      "Epoch 85/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7501 - acc: 0.7388 - val_loss: 0.7736 - val_acc: 0.7444\n",
      "Epoch 86/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7526 - acc: 0.7367 - val_loss: 0.6848 - val_acc: 0.7741\n",
      "Epoch 87/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7456 - acc: 0.7406 - val_loss: 0.6891 - val_acc: 0.7762\n",
      "Epoch 88/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7406 - acc: 0.7413 - val_loss: 0.6415 - val_acc: 0.7862\n",
      "Epoch 89/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7419 - acc: 0.7416 - val_loss: 0.6456 - val_acc: 0.7821\n",
      "Epoch 90/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7425 - acc: 0.7424 - val_loss: 0.7703 - val_acc: 0.7490\n",
      "Epoch 91/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7405 - acc: 0.7433 - val_loss: 0.7532 - val_acc: 0.7447\n",
      "Epoch 92/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7380 - acc: 0.7417 - val_loss: 0.6794 - val_acc: 0.7710\n",
      "Epoch 93/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7365 - acc: 0.7432 - val_loss: 0.6837 - val_acc: 0.7714\n",
      "Epoch 94/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7312 - acc: 0.7447 - val_loss: 0.6835 - val_acc: 0.7649\n",
      "Epoch 95/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7364 - acc: 0.7445 - val_loss: 0.7051 - val_acc: 0.7676\n",
      "Epoch 96/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7258 - acc: 0.7477 - val_loss: 0.7518 - val_acc: 0.7530\n",
      "Epoch 97/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7303 - acc: 0.7448 - val_loss: 0.6544 - val_acc: 0.7818\n",
      "Epoch 98/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7295 - acc: 0.7459 - val_loss: 0.6584 - val_acc: 0.7810\n",
      "Epoch 99/150\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.7265 - acc: 0.7491 - val_loss: 0.6665 - val_acc: 0.7836\n",
      "Epoch 100/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7274 - acc: 0.7493 - val_loss: 0.6803 - val_acc: 0.7765\n",
      "Epoch 101/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7241 - acc: 0.7468 - val_loss: 0.6638 - val_acc: 0.7809\n",
      "Epoch 102/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7199 - acc: 0.7488 - val_loss: 0.6788 - val_acc: 0.7779\n",
      "Epoch 103/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7251 - acc: 0.7458 - val_loss: 0.7514 - val_acc: 0.7581\n",
      "Epoch 104/150\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.7241 - acc: 0.7470 - val_loss: 0.8117 - val_acc: 0.7396\n",
      "Epoch 105/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7261 - acc: 0.7475 - val_loss: 0.7284 - val_acc: 0.7632\n",
      "Epoch 106/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7149 - acc: 0.7484 - val_loss: 0.7227 - val_acc: 0.7623\n",
      "Epoch 107/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7202 - acc: 0.7499 - val_loss: 0.7017 - val_acc: 0.7676\n",
      "Epoch 108/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7105 - acc: 0.7503 - val_loss: 0.6427 - val_acc: 0.7858\n",
      "Epoch 109/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7094 - acc: 0.7513 - val_loss: 0.6571 - val_acc: 0.7849\n",
      "Epoch 110/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7125 - acc: 0.7534 - val_loss: 0.6692 - val_acc: 0.7799\n",
      "Epoch 111/150\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.7160 - acc: 0.7490 - val_loss: 0.7368 - val_acc: 0.7642\n",
      "Epoch 112/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7108 - acc: 0.7546 - val_loss: 0.6526 - val_acc: 0.7809\n",
      "Epoch 113/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7103 - acc: 0.7501 - val_loss: 0.6865 - val_acc: 0.7729\n",
      "Epoch 114/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7062 - acc: 0.7541 - val_loss: 0.6338 - val_acc: 0.7877\n",
      "Epoch 115/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7018 - acc: 0.7566 - val_loss: 0.6841 - val_acc: 0.7778\n",
      "Epoch 116/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7085 - acc: 0.7528 - val_loss: 0.7106 - val_acc: 0.7645\n",
      "Epoch 117/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7058 - acc: 0.7550 - val_loss: 0.7549 - val_acc: 0.7595\n",
      "Epoch 118/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7009 - acc: 0.7550 - val_loss: 0.6651 - val_acc: 0.7759\n",
      "Epoch 119/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.7043 - acc: 0.7546 - val_loss: 0.7290 - val_acc: 0.7620\n",
      "Epoch 120/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6987 - acc: 0.7536 - val_loss: 0.6619 - val_acc: 0.7871\n",
      "Epoch 121/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7000 - acc: 0.7546 - val_loss: 0.7752 - val_acc: 0.7471\n",
      "Epoch 122/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6987 - acc: 0.7541 - val_loss: 0.6482 - val_acc: 0.7852\n",
      "Epoch 123/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6956 - acc: 0.7601 - val_loss: 0.7060 - val_acc: 0.7701\n",
      "Epoch 124/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6958 - acc: 0.7571 - val_loss: 0.8256 - val_acc: 0.7352\n",
      "Epoch 125/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6971 - acc: 0.7550 - val_loss: 0.6502 - val_acc: 0.7883\n",
      "Epoch 126/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6898 - acc: 0.7599 - val_loss: 0.6824 - val_acc: 0.7712\n",
      "Epoch 127/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6954 - acc: 0.7560 - val_loss: 0.6755 - val_acc: 0.7741\n",
      "Epoch 128/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6949 - acc: 0.7607 - val_loss: 0.7309 - val_acc: 0.7687\n",
      "Epoch 129/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6950 - acc: 0.7558 - val_loss: 0.6997 - val_acc: 0.7770\n",
      "Epoch 130/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6935 - acc: 0.7594 - val_loss: 0.6816 - val_acc: 0.7731\n",
      "Epoch 131/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6881 - acc: 0.7592 - val_loss: 0.6201 - val_acc: 0.7981\n",
      "Epoch 132/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6897 - acc: 0.7582 - val_loss: 0.6791 - val_acc: 0.7718\n",
      "Epoch 133/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6912 - acc: 0.7592 - val_loss: 0.6200 - val_acc: 0.7927\n",
      "Epoch 134/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6942 - acc: 0.7592 - val_loss: 0.7140 - val_acc: 0.7719\n",
      "Epoch 135/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6840 - acc: 0.7614 - val_loss: 0.6038 - val_acc: 0.7967\n",
      "Epoch 136/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6888 - acc: 0.7620 - val_loss: 0.6626 - val_acc: 0.7820\n",
      "Epoch 137/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6829 - acc: 0.7607 - val_loss: 0.6582 - val_acc: 0.7838\n",
      "Epoch 138/150\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6824 - acc: 0.7607 - val_loss: 0.6442 - val_acc: 0.7896\n",
      "Epoch 139/150\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.6802 - acc: 0.7624 - val_loss: 0.6914 - val_acc: 0.7682\n",
      "Epoch 140/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6827 - acc: 0.7627 - val_loss: 0.6044 - val_acc: 0.7976\n",
      "Epoch 141/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6752 - acc: 0.7669 - val_loss: 0.7020 - val_acc: 0.7713\n",
      "Epoch 142/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6810 - acc: 0.7645 - val_loss: 0.6252 - val_acc: 0.7979\n",
      "Epoch 143/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6740 - acc: 0.7671 - val_loss: 0.6128 - val_acc: 0.7962\n",
      "Epoch 144/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6762 - acc: 0.7631 - val_loss: 0.6661 - val_acc: 0.7827\n",
      "Epoch 145/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6748 - acc: 0.7647 - val_loss: 0.5948 - val_acc: 0.8027\n",
      "Epoch 146/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6752 - acc: 0.7631 - val_loss: 0.6370 - val_acc: 0.7939\n",
      "Epoch 147/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6763 - acc: 0.7653 - val_loss: 0.7443 - val_acc: 0.7618\n",
      "Epoch 148/150\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6779 - acc: 0.7649 - val_loss: 0.6295 - val_acc: 0.7894\n",
      "Epoch 149/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6674 - acc: 0.7642 - val_loss: 0.7642 - val_acc: 0.7592\n",
      "Epoch 150/150\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.6718 - acc: 0.7656 - val_loss: 0.6509 - val_acc: 0.7811\n"
     ]
    }
   ],
   "source": [
    "# Fits the model on batches with real-time data augmentation\n",
    "\n",
    "history_model_3 = model.fit(temp_data.flow(x_tr, y_tr, batch_size=40), steps_per_epoch=x_tr.shape[0] // 40, epochs=150, validation_data=(x_val, y_val), validation_batch_size=x_val.shape[0] // 40)\n",
    "model.save('model_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history_model_3.history['acc']\n",
    "val_acc = history_model_3.history['val_acc']\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train (again) and evaluate the model\n",
    "To this end, you have found the \"best\" hyper-parameters.\n",
    "Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "Evaluate your model on the test set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on the entire training set\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<Compile your model again (using the same hyper-parameters you tuned above)>\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (4, 4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(learning_rate = lr) , metrics=['acc'])\n",
    "\n",
    "# Data augmentation\n",
    "\n",
    "temp_data = ImageDataGenerator( rotation_range=20, height_shift_range=0.2, width_shift_range=0.2, \n",
    "                               zoom_range = 0.2, shear_range = 0.2, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1250/1250 [==============================] - 18s 13ms/step - loss: 1.6739 - acc: 0.4005\n",
      "Epoch 2/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4322 - acc: 0.4883\n",
      "Epoch 3/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.3354 - acc: 0.5220\n",
      "Epoch 4/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.2737 - acc: 0.5492\n",
      "Epoch 5/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.2268 - acc: 0.5642\n",
      "Epoch 6/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.1927 - acc: 0.5767\n",
      "Epoch 7/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.1588 - acc: 0.5890\n",
      "Epoch 8/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.1307 - acc: 0.6025\n",
      "Epoch 9/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.1073 - acc: 0.6101\n",
      "Epoch 10/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.0878 - acc: 0.6177\n",
      "Epoch 11/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.0688 - acc: 0.6219\n",
      "Epoch 12/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.0429 - acc: 0.6336\n",
      "Epoch 13/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.0266 - acc: 0.6398\n",
      "Epoch 14/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.0172 - acc: 0.6430\n",
      "Epoch 15/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.0083 - acc: 0.6481\n",
      "Epoch 16/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.9929 - acc: 0.6525\n",
      "Epoch 17/150\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 0.9748 - acc: 0.6582\n",
      "Epoch 18/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.9654 - acc: 0.6617\n",
      "Epoch 19/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.9588 - acc: 0.6651\n",
      "Epoch 20/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.9479 - acc: 0.6685\n",
      "Epoch 21/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.9440 - acc: 0.6708\n",
      "Epoch 22/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.9322 - acc: 0.6736\n",
      "Epoch 23/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.9289 - acc: 0.6749\n",
      "Epoch 24/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.9208 - acc: 0.6796\n",
      "Epoch 25/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.9123 - acc: 0.6814\n",
      "Epoch 26/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.9020 - acc: 0.6853\n",
      "Epoch 27/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.8997 - acc: 0.6827\n",
      "Epoch 28/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.8941 - acc: 0.6898\n",
      "Epoch 29/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.8916 - acc: 0.6895\n",
      "Epoch 30/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.8778 - acc: 0.6945\n",
      "Epoch 31/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.8773 - acc: 0.6953\n",
      "Epoch 32/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.8709 - acc: 0.6961\n",
      "Epoch 33/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.8684 - acc: 0.6953\n",
      "Epoch 34/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.8557 - acc: 0.7014\n",
      "Epoch 35/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.8542 - acc: 0.7026\n",
      "Epoch 36/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.8504 - acc: 0.7041\n",
      "Epoch 37/150\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 0.8457 - acc: 0.7049\n",
      "Epoch 38/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.8425 - acc: 0.7038\n",
      "Epoch 39/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.8379 - acc: 0.7080\n",
      "Epoch 40/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.8300 - acc: 0.7090\n",
      "Epoch 41/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.8337 - acc: 0.7111\n",
      "Epoch 42/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.8302 - acc: 0.7104\n",
      "Epoch 43/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.8239 - acc: 0.7141\n",
      "Epoch 44/150\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 0.8254 - acc: 0.7125\n",
      "Epoch 45/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.8154 - acc: 0.7180\n",
      "Epoch 46/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.8169 - acc: 0.7160\n",
      "Epoch 47/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.8129 - acc: 0.7155\n",
      "Epoch 48/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.8085 - acc: 0.7182\n",
      "Epoch 49/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7983 - acc: 0.7228\n",
      "Epoch 50/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7992 - acc: 0.7221\n",
      "Epoch 51/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7977 - acc: 0.7209\n",
      "Epoch 52/150\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 0.7914 - acc: 0.7240\n",
      "Epoch 53/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7932 - acc: 0.7228\n",
      "Epoch 54/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7872 - acc: 0.7258\n",
      "Epoch 55/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7847 - acc: 0.7257\n",
      "Epoch 56/150\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 0.7785 - acc: 0.7296\n",
      "Epoch 57/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7805 - acc: 0.7279\n",
      "Epoch 58/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7801 - acc: 0.7270\n",
      "Epoch 59/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7756 - acc: 0.7292\n",
      "Epoch 60/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7752 - acc: 0.7303\n",
      "Epoch 61/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7724 - acc: 0.7312\n",
      "Epoch 62/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.7703 - acc: 0.7318\n",
      "Epoch 63/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7687 - acc: 0.7350\n",
      "Epoch 64/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7633 - acc: 0.7361\n",
      "Epoch 65/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7645 - acc: 0.7343\n",
      "Epoch 66/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7580 - acc: 0.7346\n",
      "Epoch 67/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.7612 - acc: 0.7347\n",
      "Epoch 68/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7566 - acc: 0.7365\n",
      "Epoch 69/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7520 - acc: 0.7375\n",
      "Epoch 70/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.7540 - acc: 0.7390\n",
      "Epoch 71/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7491 - acc: 0.7355\n",
      "Epoch 72/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.7494 - acc: 0.7384\n",
      "Epoch 73/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.7441 - acc: 0.7409\n",
      "Epoch 74/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7404 - acc: 0.7443\n",
      "Epoch 75/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.7409 - acc: 0.7423\n",
      "Epoch 76/150\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 0.7416 - acc: 0.7429\n",
      "Epoch 77/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7389 - acc: 0.7444\n",
      "Epoch 78/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7333 - acc: 0.7436\n",
      "Epoch 79/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.7351 - acc: 0.7449\n",
      "Epoch 80/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7331 - acc: 0.7438\n",
      "Epoch 81/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7313 - acc: 0.7470\n",
      "Epoch 82/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.7243 - acc: 0.7482\n",
      "Epoch 83/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7260 - acc: 0.7498\n",
      "Epoch 84/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7249 - acc: 0.7475\n",
      "Epoch 85/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.7245 - acc: 0.7484\n",
      "Epoch 86/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7239 - acc: 0.7490\n",
      "Epoch 87/150\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 0.7172 - acc: 0.7499\n",
      "Epoch 88/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7222 - acc: 0.7472\n",
      "Epoch 89/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.7198 - acc: 0.7513\n",
      "Epoch 90/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7146 - acc: 0.7529\n",
      "Epoch 91/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.7142 - acc: 0.7524\n",
      "Epoch 92/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7153 - acc: 0.7524\n",
      "Epoch 93/150\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 0.7079 - acc: 0.7538\n",
      "Epoch 94/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7122 - acc: 0.7533\n",
      "Epoch 95/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7151 - acc: 0.7520\n",
      "Epoch 96/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7142 - acc: 0.7511\n",
      "Epoch 97/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.7031 - acc: 0.7552\n",
      "Epoch 98/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7151 - acc: 0.7530\n",
      "Epoch 99/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.7006 - acc: 0.7570\n",
      "Epoch 100/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7056 - acc: 0.7551\n",
      "Epoch 101/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7016 - acc: 0.7576\n",
      "Epoch 102/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7014 - acc: 0.7565\n",
      "Epoch 103/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.6970 - acc: 0.7580\n",
      "Epoch 104/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6971 - acc: 0.7588\n",
      "Epoch 105/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.6950 - acc: 0.7585\n",
      "Epoch 106/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6965 - acc: 0.7585\n",
      "Epoch 107/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.6919 - acc: 0.7613\n",
      "Epoch 108/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.6947 - acc: 0.7586\n",
      "Epoch 109/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6955 - acc: 0.7585\n",
      "Epoch 110/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.6846 - acc: 0.7609\n",
      "Epoch 111/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.6869 - acc: 0.7618\n",
      "Epoch 112/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6885 - acc: 0.7604\n",
      "Epoch 113/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.6837 - acc: 0.7620\n",
      "Epoch 114/150\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 0.6918 - acc: 0.7600\n",
      "Epoch 115/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6861 - acc: 0.7624\n",
      "Epoch 116/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6823 - acc: 0.7642\n",
      "Epoch 117/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.6790 - acc: 0.7624\n",
      "Epoch 118/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.6863 - acc: 0.7637\n",
      "Epoch 119/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.6822 - acc: 0.7617\n",
      "Epoch 120/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.6836 - acc: 0.7646\n",
      "Epoch 121/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.6757 - acc: 0.7642\n",
      "Epoch 122/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.6743 - acc: 0.7660\n",
      "Epoch 123/150\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 0.6824 - acc: 0.7631\n",
      "Epoch 124/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6751 - acc: 0.7650\n",
      "Epoch 125/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.6689 - acc: 0.7699\n",
      "Epoch 126/150\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 0.6741 - acc: 0.7679\n",
      "Epoch 127/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6686 - acc: 0.7664\n",
      "Epoch 128/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.6750 - acc: 0.7655\n",
      "Epoch 129/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6688 - acc: 0.7665\n",
      "Epoch 130/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6702 - acc: 0.7675\n",
      "Epoch 131/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6739 - acc: 0.7657\n",
      "Epoch 132/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6711 - acc: 0.7675\n",
      "Epoch 133/150\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 0.6680 - acc: 0.7700\n",
      "Epoch 134/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.6664 - acc: 0.7670\n",
      "Epoch 135/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6611 - acc: 0.7713\n",
      "Epoch 136/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6620 - acc: 0.7706\n",
      "Epoch 137/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6609 - acc: 0.7699\n",
      "Epoch 138/150\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 0.6620 - acc: 0.7714\n",
      "Epoch 139/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.6626 - acc: 0.7694\n",
      "Epoch 140/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6592 - acc: 0.7717\n",
      "Epoch 141/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6575 - acc: 0.7716\n",
      "Epoch 142/150\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 0.6600 - acc: 0.7726\n",
      "Epoch 143/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.6605 - acc: 0.7709\n",
      "Epoch 144/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6585 - acc: 0.7726\n",
      "Epoch 145/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6612 - acc: 0.7695\n",
      "Epoch 146/150\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 0.6527 - acc: 0.7758\n",
      "Epoch 147/150\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6518 - acc: 0.7722\n",
      "Epoch 148/150\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.6511 - acc: 0.7732\n",
      "Epoch 149/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.6537 - acc: 0.7731\n",
      "Epoch 150/150\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.6541 - acc: 0.7733\n"
     ]
    }
   ],
   "source": [
    "# Train the model and store model parameters/loss values\n",
    "\n",
    "history_model_4 = model.fit(temp_data.flow(x_train, y_train_vec, batch_size=40), steps_per_epoch=x_tr.shape[0] // 32, epochs=150)\n",
    "model.save('model_4.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on the test set\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6738 - acc: 0.7767\n",
      "loss = 0.6738083958625793\n",
      "accuracy = 0.7767000198364258\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model performance (testing accuracy) on testing data.\n",
    "\n",
    "curr_model = load_model('model_3.h5')\n",
    "lacc = curr_model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(lacc[0]))\n",
    "print('accuracy = ' + str(lacc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6640 - acc: 0.7904\n",
      "loss = 0.6639710664749146\n",
      "accuracy = 0.7904000282287598\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model performance (testing accuracy) on testing data.\n",
    "\n",
    "curr_model = load_model('model_4.h5')\n",
    "lacc = curr_model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(lacc[0]))\n",
    "print('accuracy = ' + str(lacc[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Model using Batch Normalization and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 30, 30, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 12, 12, 64)        32832     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 12, 12, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               590080    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 627,786\n",
      "Trainable params: 627,082\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (4, 4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model optimizer and loss function\n",
    "\n",
    "lr = 0.0001\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(learning_rate=lr), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 1.6626 - acc: 0.4042 - val_loss: 1.2909 - val_acc: 0.5464\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.3339 - acc: 0.5246 - val_loss: 1.1450 - val_acc: 0.6008\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.2164 - acc: 0.5698 - val_loss: 1.0627 - val_acc: 0.6249\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.1331 - acc: 0.6003 - val_loss: 1.0147 - val_acc: 0.6442\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.0691 - acc: 0.6248 - val_loss: 0.9486 - val_acc: 0.6667\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 1.0272 - acc: 0.6398 - val_loss: 0.9513 - val_acc: 0.6667\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.9915 - acc: 0.6500 - val_loss: 0.9319 - val_acc: 0.6728\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.9596 - acc: 0.6620 - val_loss: 0.9131 - val_acc: 0.6831\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.9344 - acc: 0.6718 - val_loss: 0.9141 - val_acc: 0.6778\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.9027 - acc: 0.6859 - val_loss: 0.8755 - val_acc: 0.6984\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.8842 - acc: 0.6906 - val_loss: 0.8452 - val_acc: 0.7072\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.8651 - acc: 0.6973 - val_loss: 0.8766 - val_acc: 0.6929\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.8447 - acc: 0.7055 - val_loss: 0.9242 - val_acc: 0.6848\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.8208 - acc: 0.7121 - val_loss: 0.7988 - val_acc: 0.7300\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.8041 - acc: 0.7197 - val_loss: 0.7729 - val_acc: 0.7333\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.7890 - acc: 0.7267 - val_loss: 0.7714 - val_acc: 0.7379\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.7671 - acc: 0.7329 - val_loss: 0.7699 - val_acc: 0.7374\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.7615 - acc: 0.7328 - val_loss: 0.7941 - val_acc: 0.7318\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.7463 - acc: 0.7412 - val_loss: 0.7214 - val_acc: 0.7569\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.7290 - acc: 0.7460 - val_loss: 0.7576 - val_acc: 0.7416\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.7149 - acc: 0.7531 - val_loss: 0.7283 - val_acc: 0.7556\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.7037 - acc: 0.7544 - val_loss: 0.7186 - val_acc: 0.7566\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.6928 - acc: 0.7600 - val_loss: 0.7229 - val_acc: 0.7539\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.6810 - acc: 0.7651 - val_loss: 0.7138 - val_acc: 0.7610\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.6644 - acc: 0.7695 - val_loss: 0.6929 - val_acc: 0.7634\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6578 - acc: 0.7732 - val_loss: 0.7390 - val_acc: 0.7470\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6465 - acc: 0.7778 - val_loss: 0.6974 - val_acc: 0.7611\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.6403 - acc: 0.7773 - val_loss: 0.8008 - val_acc: 0.7276\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.6247 - acc: 0.7823 - val_loss: 0.7187 - val_acc: 0.7555\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.6148 - acc: 0.7867 - val_loss: 0.6853 - val_acc: 0.7668\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.6087 - acc: 0.7878 - val_loss: 0.7039 - val_acc: 0.7624\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.5992 - acc: 0.7926 - val_loss: 0.6858 - val_acc: 0.7696\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.5899 - acc: 0.7964 - val_loss: 0.7350 - val_acc: 0.7538\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.5810 - acc: 0.8007 - val_loss: 0.6719 - val_acc: 0.7748\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.5717 - acc: 0.8023 - val_loss: 0.6662 - val_acc: 0.7736\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.5658 - acc: 0.8058 - val_loss: 0.6952 - val_acc: 0.7664\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.5524 - acc: 0.8105 - val_loss: 0.6778 - val_acc: 0.7729\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.5494 - acc: 0.8092 - val_loss: 0.6764 - val_acc: 0.7739\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.5368 - acc: 0.8151 - val_loss: 0.6941 - val_acc: 0.7694\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.5292 - acc: 0.8169 - val_loss: 0.6521 - val_acc: 0.7839\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.5245 - acc: 0.8199 - val_loss: 0.7296 - val_acc: 0.7546\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.5172 - acc: 0.8223 - val_loss: 0.6486 - val_acc: 0.7821\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.5078 - acc: 0.8244 - val_loss: 0.6806 - val_acc: 0.7736\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.5039 - acc: 0.8274 - val_loss: 0.6604 - val_acc: 0.7815\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.4983 - acc: 0.8303 - val_loss: 0.6755 - val_acc: 0.7731\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.4912 - acc: 0.8305 - val_loss: 0.6730 - val_acc: 0.7713\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.4823 - acc: 0.8341 - val_loss: 0.7536 - val_acc: 0.7620\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.4821 - acc: 0.8329 - val_loss: 0.6835 - val_acc: 0.7705\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.4747 - acc: 0.8359 - val_loss: 0.6595 - val_acc: 0.7825\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.4655 - acc: 0.8385 - val_loss: 0.6478 - val_acc: 0.7849\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.4581 - acc: 0.8407 - val_loss: 0.6603 - val_acc: 0.7810\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.4545 - acc: 0.8431 - val_loss: 0.6566 - val_acc: 0.7820\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.4478 - acc: 0.8443 - val_loss: 0.6379 - val_acc: 0.7901\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.4415 - acc: 0.8494 - val_loss: 0.6696 - val_acc: 0.7768\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.4335 - acc: 0.8513 - val_loss: 0.6495 - val_acc: 0.7906\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.4319 - acc: 0.8517 - val_loss: 0.6724 - val_acc: 0.7762\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.4291 - acc: 0.8527 - val_loss: 0.6938 - val_acc: 0.7751\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.4250 - acc: 0.8550 - val_loss: 0.6356 - val_acc: 0.7913\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.4198 - acc: 0.8559 - val_loss: 0.6472 - val_acc: 0.7843\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.4087 - acc: 0.8590 - val_loss: 0.6809 - val_acc: 0.7799\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.4122 - acc: 0.8593 - val_loss: 0.6534 - val_acc: 0.7812\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3985 - acc: 0.8642 - val_loss: 0.6783 - val_acc: 0.7822\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3957 - acc: 0.8624 - val_loss: 0.6662 - val_acc: 0.7804\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3908 - acc: 0.8667 - val_loss: 0.7031 - val_acc: 0.7661\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3874 - acc: 0.8677 - val_loss: 0.6270 - val_acc: 0.7943\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3880 - acc: 0.8677 - val_loss: 0.6366 - val_acc: 0.7901\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3772 - acc: 0.8719 - val_loss: 0.6492 - val_acc: 0.7863\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3750 - acc: 0.8706 - val_loss: 0.6537 - val_acc: 0.7848\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3734 - acc: 0.8717 - val_loss: 0.6371 - val_acc: 0.7936\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3667 - acc: 0.8741 - val_loss: 0.6934 - val_acc: 0.7787\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3658 - acc: 0.8766 - val_loss: 0.6505 - val_acc: 0.7882\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3615 - acc: 0.8753 - val_loss: 0.6788 - val_acc: 0.7749\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3563 - acc: 0.8805 - val_loss: 0.7246 - val_acc: 0.7689\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3491 - acc: 0.8819 - val_loss: 0.6983 - val_acc: 0.7724\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3495 - acc: 0.8811 - val_loss: 0.6874 - val_acc: 0.7741\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3422 - acc: 0.8834 - val_loss: 0.6711 - val_acc: 0.7849\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3358 - acc: 0.8839 - val_loss: 0.7697 - val_acc: 0.7588\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3418 - acc: 0.8827 - val_loss: 0.6564 - val_acc: 0.7867\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3385 - acc: 0.8823 - val_loss: 0.6734 - val_acc: 0.7859\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3342 - acc: 0.8855 - val_loss: 0.6942 - val_acc: 0.7782\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3299 - acc: 0.8867 - val_loss: 0.6606 - val_acc: 0.7891\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3239 - acc: 0.8884 - val_loss: 0.6817 - val_acc: 0.7863\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3217 - acc: 0.8908 - val_loss: 0.7015 - val_acc: 0.7867\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3256 - acc: 0.8878 - val_loss: 0.7151 - val_acc: 0.7819\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3268 - acc: 0.8873 - val_loss: 0.6960 - val_acc: 0.7804\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3177 - acc: 0.8917 - val_loss: 0.7188 - val_acc: 0.7876\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3106 - acc: 0.8926 - val_loss: 0.6682 - val_acc: 0.7942\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3087 - acc: 0.8936 - val_loss: 0.6655 - val_acc: 0.7888\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3082 - acc: 0.8946 - val_loss: 0.7700 - val_acc: 0.7650\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3057 - acc: 0.8965 - val_loss: 0.6781 - val_acc: 0.7882\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3026 - acc: 0.8965 - val_loss: 0.6638 - val_acc: 0.7889\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2986 - acc: 0.8969 - val_loss: 0.6850 - val_acc: 0.7872\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2904 - acc: 0.9010 - val_loss: 0.6626 - val_acc: 0.7827\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2926 - acc: 0.9006 - val_loss: 0.6758 - val_acc: 0.7870\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2918 - acc: 0.8996 - val_loss: 0.7069 - val_acc: 0.7892\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2876 - acc: 0.9017 - val_loss: 0.6668 - val_acc: 0.7846\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2884 - acc: 0.9016 - val_loss: 0.6892 - val_acc: 0.7828\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2834 - acc: 0.9031 - val_loss: 0.6631 - val_acc: 0.7844\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2872 - acc: 0.9021 - val_loss: 0.7385 - val_acc: 0.7733\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2816 - acc: 0.9041 - val_loss: 0.7698 - val_acc: 0.7770\n"
     ]
    }
   ],
   "source": [
    "# Train the model and store model parameters/loss values\n",
    "\n",
    "history_model_5 = model.fit(x_tr, y_tr, batch_size=40, epochs=100, validation_data=(x_val, y_val))\n",
    "model.save('model_5.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the training and validation loss curve versus epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history_model_5.history['acc']\n",
    "val_acc = history_model_5.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train (again) and evaluate the model\n",
    "To this end, you have found the \"best\" hyper-parameters.\n",
    "Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "Evaluate your model on the test set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on the entire training set\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<Compile your model again (using the same hyper-parameters you tuned above)>\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (4, 4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(learning_rate=lr), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 10s 7ms/step - loss: 1.6347 - acc: 0.4141\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.3078 - acc: 0.5313\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.1872 - acc: 0.5811\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.1049 - acc: 0.6104\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0417 - acc: 0.6333\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0046 - acc: 0.6475\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.9650 - acc: 0.6603\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.9331 - acc: 0.6717\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.9060 - acc: 0.6836\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.8777 - acc: 0.6942\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.8560 - acc: 0.7022\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.8314 - acc: 0.7094\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.8135 - acc: 0.7158\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7940 - acc: 0.7248\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7799 - acc: 0.7270\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.7645 - acc: 0.7339\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.7473 - acc: 0.7396\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.7307 - acc: 0.7463\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.7165 - acc: 0.7522\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.7021 - acc: 0.7566\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.6939 - acc: 0.7562\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.6741 - acc: 0.7671\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.6638 - acc: 0.7709\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.6557 - acc: 0.7722\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.6391 - acc: 0.7779\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.6318 - acc: 0.7823\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.6248 - acc: 0.7832\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.6166 - acc: 0.7872\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.6056 - acc: 0.7910\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.5902 - acc: 0.7971\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.5892 - acc: 0.7975\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.5771 - acc: 0.8012\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.5707 - acc: 0.8029\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.5587 - acc: 0.8070\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5533 - acc: 0.8095\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.5426 - acc: 0.8119\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.5373 - acc: 0.8152\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.5284 - acc: 0.8164\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.5225 - acc: 0.8185\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.5174 - acc: 0.8215\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.5089 - acc: 0.8223\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5011 - acc: 0.8280\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4995 - acc: 0.8289\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4881 - acc: 0.8312\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4849 - acc: 0.8329\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4761 - acc: 0.8351\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4727 - acc: 0.8375\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4669 - acc: 0.8404\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4590 - acc: 0.8427\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4569 - acc: 0.8410\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4485 - acc: 0.8450\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.4489 - acc: 0.8446\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4395 - acc: 0.8473\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4367 - acc: 0.8495\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4326 - acc: 0.8505\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4266 - acc: 0.8536\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.4229 - acc: 0.8531\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4221 - acc: 0.8549\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4106 - acc: 0.8592\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4073 - acc: 0.8601\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4018 - acc: 0.8610\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4028 - acc: 0.8612\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3985 - acc: 0.8607\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3882 - acc: 0.8653\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3908 - acc: 0.8660\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3898 - acc: 0.8636\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3785 - acc: 0.8710\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3746 - acc: 0.8724\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.3751 - acc: 0.8707\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3711 - acc: 0.8720\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.3670 - acc: 0.8726\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3642 - acc: 0.8731\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3629 - acc: 0.8753\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3587 - acc: 0.8770\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3551 - acc: 0.8783\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3526 - acc: 0.8795\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3500 - acc: 0.8788\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3487 - acc: 0.8778\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.3458 - acc: 0.8805\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.3384 - acc: 0.8840\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.3360 - acc: 0.8843\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3346 - acc: 0.8838\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3345 - acc: 0.8873\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3269 - acc: 0.8870\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3278 - acc: 0.8866\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3221 - acc: 0.8898\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3208 - acc: 0.8887\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3206 - acc: 0.8896\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.3199 - acc: 0.8897\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3161 - acc: 0.8903\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.3124 - acc: 0.8917\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3077 - acc: 0.8935\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3120 - acc: 0.8930\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.3070 - acc: 0.8947\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3031 - acc: 0.8947\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2987 - acc: 0.8957\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2946 - acc: 0.8981\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.2981 - acc: 0.8973\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.2901 - acc: 0.8997\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.2934 - acc: 0.8993\n"
     ]
    }
   ],
   "source": [
    "# Train the model and store model parameters/loss values\n",
    "\n",
    "history_model_6 = model.fit(x_train, y_train_vec, batch_size=40, epochs=100)\n",
    "model.save('model_6.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on the test set\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7733 - acc: 0.7735\n",
      "loss = 0.7732677459716797\n",
      "accuracy = 0.7735000252723694\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model performance (testing accuracy) on testing data.\n",
    "\n",
    "curr_model = load_model('model_5.h5')\n",
    "lacc = curr_model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(lacc[0]))\n",
    "print('accuracy = ' + str(lacc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7335 - acc: 0.7812\n",
      "loss = 0.7335073351860046\n",
      "accuracy = 0.7811999917030334\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model performance (testing accuracy) on testing data.\n",
    "\n",
    "curr_model = load_model('model_6.h5')\n",
    "lacc = curr_model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(lacc[0]))\n",
    "print('accuracy = ' + str(lacc[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparision and Analysis:\n",
    "*Normal CNN model:* is not that efficient and has an accuracy of 69 % and after using full training dataset it achieves accuracy of 70 %. *My first model* which uses data augmentation and batch normalization has a accuracy of 66 % and after using full training dataset it achieves has accuracy of ~78 %. *My second and final model* which uses batch normaliztion and dropout has an accuracy of 78 % and after using full training dataset it achieves an accuracy of ~80 %.\n",
    "\n",
    "*Hence, I think model 2 is the best model, I could make considering the time and the limited availability of Google Colab's GPU feature.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_venv",
   "language": "python",
   "name": "tf_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
